{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriol\\anaconda3\\envs\\DL\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: ebnerd_demo\n",
      "Loading GloVe vectors from saved file: ../Data/glove_vectors.pt\n",
      "\n",
      "\n",
      "Statistics for Train Dataset:\n",
      "Browsed News - Min: 5, Max: 1000, Mean: 182.61, Std: 180.37\n",
      "Candidate News - Min: 5, Max: 100, Mean: 11.24, Std: 7.92\n",
      "\n",
      "\n",
      "\n",
      "Statistics for Validation Dataset:\n",
      "Browsed News - Min: 5, Max: 1000, Mean: 276.52, Std: 219.08\n",
      "Candidate News - Min: 5, Max: 93, Mean: 12.03, Std: 9.32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from data_loader import *\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "browsed news:  torch.Size([2554, 20, 114]) \n",
      "candidate news:  torch.Size([2554, 20, 114]) \n",
      "clicked news:  torch.Size([2554, 20])\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nbrowsed news: \", browsed_news_train.shape\n",
    "      , \"\\ncandidate news: \", candidate_news_train.shape\n",
    "      , \"\\nclicked news: \", clicked_news_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ------NEWS ENCODER------\n",
      "input shape: torch.Size([16, 114])\n",
      "output shape: torch.Size([16, 300])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 16\n",
    "\n",
    "### Test news encoder\n",
    "print(\"\\n ------NEWS ENCODER------\")\n",
    "\n",
    "word_embedding_matrix = glove_vectors  # Assume glove_vectors are loaded and of correct size\n",
    "attention_dim = 200\n",
    "# Instantiate the model\n",
    "news_encoder = NewsEncoder(embed_size=300, heads=15, word_embedding_matrix=word_embedding_matrix, attention_dim=attention_dim)\n",
    "\n",
    "# Random input\n",
    "\n",
    "x = browsed_news_train[:batch_size, 1, :] #[Batch size, 1 news, 26 words]\n",
    "\n",
    "output = news_encoder(x)\n",
    "\n",
    "print(\"input shape:\", x.shape)\n",
    "print(\"output shape:\", output.shape) # News encoder works fine\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ------USER ENCODER------\n",
      "input shape: torch.Size([16, 20, 300])\n",
      "output shape: torch.Size([16, 300])\n"
     ]
    }
   ],
   "source": [
    "### Test user encoder\n",
    "print('\\n ------USER ENCODER------')\n",
    "\n",
    "user_encoder = UserEncoder(embed_size=300, heads=15, attention_dim=200)\n",
    "\n",
    "x = browsed_news_train[:batch_size, :, :] #[Batch size, all news, 26 words]\n",
    "\n",
    "e = [news_encoder(news) for news in x] # Apply the news encoder to each news article\n",
    "e = torch.stack(e, dim=0)\n",
    "\n",
    "output = user_encoder(e)\n",
    "\n",
    "print(\"input shape:\", e.shape)\n",
    "print(\"output shape:\", output.shape) # User encoder works fine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -----COMPLETE MODEL------\n",
      "\n",
      "Input shape: Browsed = torch.Size([3, 20, 114]), Candidate = torch.Size([3, 20, 114])\n",
      "Output shape: Click = torch.Size([3, 20])\n",
      "\n",
      "Sum of probabilities: tensor([1.0000, 1.0000, 1.0000], grad_fn=<SumBackward1>)\n",
      "\n",
      "Clicked indices: True = tensor([ 4, 15,  0]), Predicted = tensor([0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### Test full model\n",
    "print('\\n -----COMPLETE MODEL------') \n",
    "\n",
    "batch_size = 3\n",
    "\n",
    "model_final = NRMS(embed_size=300, heads=15, word_embedding_matrix=glove_vectors, attention_dim=200)\n",
    "\n",
    "browsed_news_batch = browsed_news_train[:batch_size, :, :] #[Batch size, all news, 26 words]\n",
    "candidate_news_batch = candidate_news_train[:batch_size, :, :] #[Batch size, all news, 26 words]\n",
    "clicked_news_batch = clicked_news_train[:batch_size, :] #[Batch size, all news]\n",
    "\n",
    "# Forward pass for the entire batch\n",
    "click = model_final(browsed_news_batch, candidate_news_batch)\n",
    "\n",
    "print(f\"\\nInput shape: Browsed = {browsed_news_batch.shape}, Candidate = {candidate_news_batch.shape}\")\n",
    "print(f\"Output shape: Click = {click.shape}\") # Full model works fine\n",
    "\n",
    "print(\"\\nSum of probabilities:\", torch.sum(click, dim=1)) # Probabilities sum to 1\n",
    "print(f\"\\nClicked indices: True = {torch.argmax(click, dim=1)}, Predicted = {torch.argmax(clicked_news_batch, dim=1)}\") # Predicted indices match true indices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Length of train_loader:  40\n",
      "\n",
      "One batch of data from train_loader: \n",
      "{'browsed_news': tensor([[271792,  21932,     48,  ...,      0,      0,      0],\n",
      "        [     2,      2,     48,  ...,      0,      0,      0],\n",
      "        [     2,      2,  32085,  ...,      0,      0,      0],\n",
      "        ...,\n",
      "        [398853,      2,      2,  ...,      0,      0,      0],\n",
      "        [     2,  12601, 354434,  ...,      0,      0,      0],\n",
      "        [398853,      2,      2,  ...,      0,      0,      0]]), 'candidate_news': tensor([[ 72313,   3883,      5,  ...,      0,      0,      0],\n",
      "        [     2,  42973,  37972,  ...,      0,      0,      0],\n",
      "        [ 93327, 314424,  67929,  ...,      0,      0,      0],\n",
      "        ...,\n",
      "        [     2,  10533,      2,  ...,      0,      0,      0],\n",
      "        [     2,     48,      2,  ...,      0,      0,      0],\n",
      "        [ 96666,     48,     74,  ...,      0,      0,      0]]), 'clicked_idx': tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.])}\n",
      "torch.Size([20, 114])\n",
      "torch.Size([20, 114])\n",
      "torch.Size([20])\n"
     ]
    }
   ],
   "source": [
    "#print length of test_loader\n",
    "print(\"\\nLength of train_loader: \", len(train_loader)) # Length of test_loader is 1\n",
    "\n",
    "\n",
    "#print one batch of data from test_loader\n",
    "print(\"\\nOne batch of data from train_loader: \")\n",
    "print(train_loader.dataset[0]) # One batch of data from test_loader is printed\n",
    "\n",
    "print(train_loader.dataset[0][\"browsed_news\"].size()) # Shape of browsed_news_train\n",
    "print(train_loader.dataset[0][\"candidate_news\"].size()) # Shape of candidate_news_train\n",
    "print(train_loader.dataset[0][\"clicked_idx\"].size()) # Shape of clicked_news_train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrms_model = NRMS(embed_size=300, heads=4, word_embedding_matrix=glove_vectors, attention_dim=128)\n",
    "# Optimizer for model\n",
    "optimizer = torch.optim.Adam(nrms_model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NRMS(\n",
       "  (news_encoder): NewsEncoder(\n",
       "    (embedding): Embedding(400004, 300, padding_idx=0)\n",
       "    (multi_head_attention): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=300, out_features=300, bias=True)\n",
       "    )\n",
       "    (additive_attention): AdditiveAttention(\n",
       "      (V_w): Linear(in_features=300, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (user_encoder): UserEncoder(\n",
       "    (multi_head_attention): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=300, out_features=300, bias=True)\n",
       "    )\n",
       "    (additive_attention): AdditiveAttention(\n",
       "      (V_w): Linear(in_features=300, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nrms_model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User histories shape:  torch.Size([64, 20, 114])\n",
      "Candidate news shape:  torch.Size([64, 20, 114])\n",
      "Labels shape:  torch.Size([64, 20])\n",
      "Labels:  tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create an iterator from the dataloader\n",
    "data_iter = iter(train_loader)\n",
    "\n",
    "# Get the first batch from the iterator\n",
    "batch = next(data_iter)\n",
    "\n",
    "user_histories = batch['browsed_news']\n",
    "candidate_news = batch['candidate_news']\n",
    "labels = batch['clicked_idx']\n",
    "\n",
    "print(\"\\nUser histories shape: \", user_histories.shape)\n",
    "print(\"Candidate news shape: \", candidate_news.shape)\n",
    "print(\"Labels shape: \", labels.shape)\n",
    "print(\"Labels: \", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "click_prob = nrms_model(user_histories, candidate_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(click_prob[0]) # Probabilities sum to 1\n",
    "no_batches, no_candidate_news = click_prob.size()\n",
    "positive_index = torch.arange(no_batches), torch.argmax(labels, dim=1)\n",
    "positive_sample = click_prob[positive_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64])\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "print(positive_index[0].size())\n",
    "print(positive_index[0])\n",
    "print(positive_index[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 19])\n",
      "tensor([[0.0542, 0.0550, 0.0529,  ..., 0.0533, 0.0493, 0.0499],\n",
      "        [0.0461, 0.0492, 0.0525,  ..., 0.0551, 0.0484, 0.0516],\n",
      "        [0.0476, 0.0530, 0.0475,  ..., 0.0467, 0.0541, 0.0521],\n",
      "        ...,\n",
      "        [0.0538, 0.0456, 0.0528,  ..., 0.0531, 0.0509, 0.0540],\n",
      "        [0.0460, 0.0443, 0.0476,  ..., 0.0525, 0.0510, 0.0545],\n",
      "        [0.0536, 0.0471, 0.0488,  ..., 0.0510, 0.0523, 0.0431]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0550, 0.0529, 0.0475,  ..., 0.0533, 0.0493, 0.0499],\n",
      "        [0.0492, 0.0525, 0.0511,  ..., 0.0551, 0.0484, 0.0516],\n",
      "        [0.0530, 0.0475, 0.0466,  ..., 0.0467, 0.0541, 0.0521],\n",
      "        ...,\n",
      "        [0.0456, 0.0528, 0.0479,  ..., 0.0531, 0.0509, 0.0540],\n",
      "        [0.0443, 0.0476, 0.0523,  ..., 0.0525, 0.0510, 0.0545],\n",
      "        [0.0471, 0.0488, 0.0503,  ..., 0.0510, 0.0523, 0.0431]],\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mask = torch.ones_like(click_prob, dtype=torch.bool)\n",
    "mask[positive_index] = False\n",
    "negative_samples = click_prob[mask].view(no_batches, -1)\n",
    "\n",
    "print(negative_samples.size())\n",
    "print(click_prob)\n",
    "print(negative_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 3, 15,  5,  2])\n",
      "tensor([[0.0475, 0.0488, 0.0476, 0.0529],\n",
      "        [0.0511, 0.0514, 0.0481, 0.0525],\n",
      "        [0.0466, 0.0475, 0.0480, 0.0475],\n",
      "        [0.0542, 0.0502, 0.0476, 0.0480],\n",
      "        [0.0493, 0.0528, 0.0520, 0.0540],\n",
      "        [0.0475, 0.0504, 0.0467, 0.0495],\n",
      "        [0.0451, 0.0506, 0.0522, 0.0538],\n",
      "        [0.0532, 0.0536, 0.0487, 0.0532],\n",
      "        [0.0481, 0.0476, 0.0520, 0.0472],\n",
      "        [0.0540, 0.0481, 0.0475, 0.0496],\n",
      "        [0.0531, 0.0484, 0.0535, 0.0514],\n",
      "        [0.0467, 0.0523, 0.0472, 0.0405],\n",
      "        [0.0488, 0.0505, 0.0476, 0.0551],\n",
      "        [0.0457, 0.0492, 0.0476, 0.0576],\n",
      "        [0.0484, 0.0543, 0.0547, 0.0475],\n",
      "        [0.0502, 0.0532, 0.0484, 0.0553],\n",
      "        [0.0442, 0.0482, 0.0505, 0.0504],\n",
      "        [0.0517, 0.0473, 0.0548, 0.0536],\n",
      "        [0.0466, 0.0528, 0.0518, 0.0516],\n",
      "        [0.0536, 0.0487, 0.0467, 0.0524],\n",
      "        [0.0483, 0.0514, 0.0535, 0.0460],\n",
      "        [0.0477, 0.0497, 0.0518, 0.0466],\n",
      "        [0.0534, 0.0462, 0.0471, 0.0519],\n",
      "        [0.0552, 0.0504, 0.0532, 0.0478],\n",
      "        [0.0427, 0.0511, 0.0474, 0.0558],\n",
      "        [0.0470, 0.0454, 0.0473, 0.0515],\n",
      "        [0.0524, 0.0472, 0.0527, 0.0493],\n",
      "        [0.0580, 0.0501, 0.0529, 0.0543],\n",
      "        [0.0521, 0.0564, 0.0487, 0.0444],\n",
      "        [0.0520, 0.0514, 0.0434, 0.0468],\n",
      "        [0.0507, 0.0424, 0.0534, 0.0550],\n",
      "        [0.0539, 0.0491, 0.0514, 0.0472],\n",
      "        [0.0530, 0.0470, 0.0530, 0.0469],\n",
      "        [0.0520, 0.0479, 0.0501, 0.0512],\n",
      "        [0.0454, 0.0522, 0.0524, 0.0516],\n",
      "        [0.0497, 0.0451, 0.0470, 0.0540],\n",
      "        [0.0504, 0.0542, 0.0522, 0.0439],\n",
      "        [0.0479, 0.0498, 0.0480, 0.0496],\n",
      "        [0.0478, 0.0520, 0.0538, 0.0527],\n",
      "        [0.0525, 0.0510, 0.0509, 0.0460],\n",
      "        [0.0484, 0.0477, 0.0510, 0.0514],\n",
      "        [0.0523, 0.0444, 0.0516, 0.0522],\n",
      "        [0.0509, 0.0498, 0.0573, 0.0549],\n",
      "        [0.0503, 0.0520, 0.0508, 0.0459],\n",
      "        [0.0462, 0.0505, 0.0477, 0.0488],\n",
      "        [0.0476, 0.0509, 0.0476, 0.0480],\n",
      "        [0.0500, 0.0469, 0.0499, 0.0505],\n",
      "        [0.0563, 0.0537, 0.0474, 0.0524],\n",
      "        [0.0464, 0.0569, 0.0466, 0.0489],\n",
      "        [0.0467, 0.0522, 0.0465, 0.0473],\n",
      "        [0.0517, 0.0486, 0.0474, 0.0527],\n",
      "        [0.0512, 0.0520, 0.0519, 0.0518],\n",
      "        [0.0514, 0.0445, 0.0513, 0.0463],\n",
      "        [0.0502, 0.0496, 0.0541, 0.0492],\n",
      "        [0.0533, 0.0527, 0.0520, 0.0482],\n",
      "        [0.0483, 0.0477, 0.0471, 0.0511],\n",
      "        [0.0433, 0.0484, 0.0535, 0.0617],\n",
      "        [0.0486, 0.0556, 0.0560, 0.0471],\n",
      "        [0.0490, 0.0527, 0.0484, 0.0572],\n",
      "        [0.0503, 0.0484, 0.0442, 0.0511],\n",
      "        [0.0549, 0.0506, 0.0561, 0.0550],\n",
      "        [0.0479, 0.0453, 0.0522, 0.0528],\n",
      "        [0.0523, 0.0524, 0.0514, 0.0476],\n",
      "        [0.0503, 0.0489, 0.0511, 0.0488]], grad_fn=<IndexBackward0>)\n"
     ]
    }
   ],
   "source": [
    "K=4\n",
    "# Use randperm instead of randint so that we don't have repetitions\n",
    "random_negative_indices = torch.randperm(no_candidate_news)[:K] \n",
    "# Neg samples for all users (using the same indexes)\n",
    "negative_samples = click_prob[:, random_negative_indices]  # [batch_size, K]\n",
    "\n",
    "print(random_negative_indices)\n",
    "print(negative_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2008, 0.1992, 0.2000, 0.1995, 0.1986, 0.1995, 0.2005, 0.1994, 0.2007,\n",
      "        0.1989, 0.1998, 0.2006, 0.1995, 0.2003, 0.1992, 0.1983, 0.2006, 0.2000,\n",
      "        0.1991, 0.1991, 0.1992, 0.1999, 0.1996, 0.1994, 0.1986, 0.1998, 0.1999,\n",
      "        0.1993, 0.2006, 0.2006, 0.1996, 0.1996, 0.1997, 0.2003, 0.2002, 0.2000,\n",
      "        0.2003, 0.2005, 0.1992, 0.1993, 0.1996, 0.2004, 0.1987, 0.1994, 0.2005,\n",
      "        0.2001, 0.2000, 0.1987, 0.2002, 0.2010, 0.1996, 0.1992, 0.1990, 0.1996,\n",
      "        0.2008, 0.2008, 0.1993, 0.1994, 0.2001, 0.1999, 0.1998, 0.2007, 0.1992,\n",
      "        0.2006], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Compute posterior prob for the positive sample\n",
    "exp_pos = torch.exp(positive_sample)  # [batch_size]\n",
    "exp_neg = torch.exp(negative_samples)  # [batch_size, K]\n",
    "sum_exp_neg = torch.sum(exp_neg, dim=1)  # [batch_size]\n",
    "pi_positive = exp_pos / (exp_pos + sum_exp_neg)  # [batch_size]\n",
    "\n",
    "print(pi_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6106, grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss = -torch.log(pi_positive).mean()\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
